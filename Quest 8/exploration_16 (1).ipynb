{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28d5553",
   "metadata": {},
   "source": [
    "# 프로젝트: 한국어 데이터로 챗봇 만들기\n",
    "⭐️ 한국어 전처리를 통해 학습 데이터셋을 구축하였다. 공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.  \n",
    "⭐️ 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다. 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.  \n",
    "⭐️ 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다. 한국어 입력문장에 맥락에 맞는 한국어로 답변을 리턴하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4067ef5e",
   "metadata": {},
   "source": [
    "---\n",
    "## 🤖 Import libraries & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7bf805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful tools\n",
    "import os\n",
    "import re\n",
    "from random import randint\n",
    "\n",
    "\n",
    "# import data tools\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# import visualization tool\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# import DL tools\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e153752",
   "metadata": {},
   "source": [
    "---\n",
    "## 🤖 Define constants, frequently used variables and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7449d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column index number of datasets\n",
    "QUESTIONS = 0\n",
    "ANSWERS = 1\n",
    "LABELS = 2\n",
    "\n",
    "\n",
    "# total samples to load from data source\n",
    "TOTAL_SAMPLES_CNT = -1    # -1 : as much as possible\n",
    "\n",
    "# maximum length of sentences in training data\n",
    "MAX_SENTENCE_LEN = 40\n",
    "\n",
    "# maximum size of vocabulary set\n",
    "VOCAB_SIZE = 2**13 + 2    # +2 for start token, end token\n",
    "\n",
    "\n",
    "\n",
    "# ML hyper parameters\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "NUM_LAYERS = 2    # the number of layers in encoder&decoder\n",
    "D_MODEL = 256     # fixed dimension of input/output of inner encoder/decoder\n",
    "NUM_HEADS = 8     # the number of heads for multihead attention \n",
    "UNITS = 512       # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1     # ratio of dropout\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "\n",
    "\n",
    "# path of data source file\n",
    "data_filename = os.getenv(\"HOME\") + \"/aiffel/transformer_chatbot/data/ChatbotData.csv\"\n",
    "\n",
    "\n",
    "\n",
    "# frequently used methods\n",
    "DIVIDER_LENGTH = 80\n",
    "def print_single_divider():\n",
    "    print(\"-\" * DIVIDER_LENGTH)\n",
    "    \n",
    "def print_double_divider():\n",
    "    print(\"=\" * DIVIDER_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b57dbe8",
   "metadata": {},
   "source": [
    "---\n",
    "## 🤖 Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae1c704",
   "metadata": {},
   "source": [
    "### 1. Define dataset loading & pre-processing methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cab05b",
   "metadata": {},
   "source": [
    "1-1. Define dataset loading method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ec910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chat_dataset(data_filename = data_filename, limit = TOTAL_SAMPLES_CNT): \n",
    "    # read data from ChatbotData.csv file\n",
    "    with open(data_filename, \"r\") as file:\n",
    "        data_source = file.readlines()\n",
    "    \n",
    "    # set maximum number of sample data\n",
    "    if limit == -1:\n",
    "        limit = len(data_source) - 1\n",
    "\n",
    "        \n",
    "    # split one sample data into Q, A, label part\n",
    "    data = {\"Q\": [], \"A\": [], \"label\": []}\n",
    "    for idx, sample in enumerate(data_source[1:limit + 1]):    # exclude column line\n",
    "        sample_split = sample.replace(\"\\n\", \"\").split(\",\")\n",
    "        \n",
    "        data[\"Q\"].append(sample_split[QUESTIONS])\n",
    "        data[\"A\"].append(sample_split[ANSWERS])\n",
    "        data[\"label\"].append(sample_split[LABELS])\n",
    "\n",
    "\n",
    "    # display result\n",
    "    if len(data[\"Q\"]) == len(data[\"A\"]) and len(data[\"Q\"]) == len(data[\"label\"]):\n",
    "        print(\"Total\", len(data[\"Q\"]), \"data samples are successfully loaded.\")\n",
    "    else:\n",
    "        print(\"Warning! The input and target data samples are not paired successfully.\")\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81379ddd",
   "metadata": {},
   "source": [
    "1-2. Define pre-processing method (removing unnecessary characters method )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d01b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_punctuations(sentence):\n",
    "    # remove space characters in bothside\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # insert space(\" \") between words and punctuations\n",
    "    #     ex. \"나는 학생이다.\" => \"나는 학생이다 .\"\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # substitute all characters except (한글, \".\", \"?\", \"!\", \",\") with space(\" \")\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣.?!,]+\", \" \", sentence)\n",
    "\n",
    "    # remove space characters that caused by substitution by regular expressions\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e02e81",
   "metadata": {},
   "source": [
    "1-3. Define pipeline method to load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879e28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_data(data_filename = data_filename, limit = TOTAL_SAMPLES_CNT):\n",
    "    # load data\n",
    "    data = load_chat_dataset(data_filename, limit)\n",
    "    questions = data[\"Q\"]\n",
    "    answers = data[\"A\"]\n",
    "\n",
    "    # pre-process data\n",
    "    questions = [divide_punctuations(q) for q in questions]\n",
    "    print_double_divider()\n",
    "    print(\"Pre-processing on\", len(questions), \"sentences in QUESTIONS data are succesfully finished!\")\n",
    "    answers = [divide_punctuations(a) for a in answers]\n",
    "    print(\"Pre-processing on\", len(answers), \"sentences in ANSWERS data are succesfully finished!\")\n",
    "    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a0c1e",
   "metadata": {},
   "source": [
    "### 2. Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9630ad14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 11823 data samples are successfully loaded.\n",
      "================================================================================\n",
      "Pre-processing on 11823 sentences in QUESTIONS data are succesfully finished!\n",
      "Pre-processing on 11823 sentences in ANSWERS data are succesfully finished!\n",
      "================================================================================\n",
      "< Preview of sample data >\n",
      "--------------------------------------------------------------------------------\n",
      "Q 7276 : 용서의 의미\n",
      "A 7276 : 단지 받아들였을 뿐이에요 .\n",
      "--------------------------------------------------------------------------------\n",
      "Q 3480 : 요즘 웃을 일이 없네\n",
      "A 3480 : 억지로라도 웃어보세요 !\n",
      "--------------------------------------------------------------------------------\n",
      "Q 10133 : 싸우다보니까 사랑했던걸 까먹어\n",
      "A 10133 : 사랑하게 된 이유를 써놓고 사랑이 힘겨울때 꺼내 읽어보세요 .\n"
     ]
    }
   ],
   "source": [
    "# load & pre-process data\n",
    "questions, answers = load_preprocess_data()\n",
    "\n",
    "\n",
    "\n",
    "# preview of sample data\n",
    "print_double_divider()\n",
    "print(\"< Preview of sample data >\")\n",
    "\n",
    "random_idx = randint(1, len(questions))\n",
    "print_single_divider()\n",
    "print(\"Q\", random_idx, \":\", questions[random_idx - 1])\n",
    "print(\"A\", random_idx, \":\", answers[random_idx - 1])\n",
    "\n",
    "random_idx = randint(1, len(questions))\n",
    "print_single_divider()\n",
    "print(\"Q\", random_idx, \":\", questions[random_idx - 1])\n",
    "print(\"A\", random_idx, \":\", answers[random_idx - 1])\n",
    "\n",
    "random_idx = randint(1, len(questions))\n",
    "print_single_divider()\n",
    "print(\"Q\", random_idx, \":\", questions[random_idx - 1])\n",
    "print(\"A\", random_idx, \":\", answers[random_idx - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c133b1e",
   "metadata": {},
   "source": [
    "### 3. Define integer encoding & padding methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f9985",
   "metadata": {},
   "source": [
    "3-1. Generate vocabulary set from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32567fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary encoder with total 8112 words is suceesfully generated!\n"
     ]
    }
   ],
   "source": [
    "# generate vocabulary set from QUESTIONS & ANSWERS data\n",
    "vocab_encoder = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size = VOCAB_SIZE - 2)\n",
    "    # target_vocab_size = VOCAB_SIZE - 2 (-2 for start token, end token)\n",
    "\n",
    "print(\"Vocabulary encoder with total\", vocab_encoder.vocab_size, \"words is suceesfully generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf27b4",
   "metadata": {},
   "source": [
    "3-2. Assign integer value for START token and END token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f36a3fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional integer idx for START and END tokens are successfully assigned!\n",
      ">>> integer index of START token : 8112\n",
      ">>> integer index of END token   : 8113\n"
     ]
    }
   ],
   "source": [
    "START_TOKEN = vocab_encoder.vocab_size\n",
    "END_TOKEN = vocab_encoder.vocab_size + 1\n",
    "\n",
    "# adjust the constant value of total vocabulary size\n",
    "VOCAB_SIZE = vocab_encoder.vocab_size + 2\n",
    "\n",
    "print(\"Additional integer idx for START and END tokens are successfully assigned!\")\n",
    "print(\">>> integer index of START token :\", START_TOKEN)\n",
    "print(\">>> integer index of END token   :\", END_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b8f0f8",
   "metadata": {},
   "source": [
    "3-3. Define interger encoding & padding methods\n",
    "   - 해당 프로젝트에서는 모듈화를 위해 integer encoding과 padding 기능을 분리하여 각각의 method로 정의\n",
    "   - 그러나 두 기능 모두 MAX_SENTENCES_LEN과 밀접한 연관이 있어 동일한 연산을 중복 수행하게 되는 trade-off 발생\n",
    "   - 연산 속도가 중요한 경우에는 encoding & padding 기능을 동시에 수행함으로써 중복 연산을 최소화할 것을 제안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00021a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_strings(sentences):\n",
    "    encoded_sentences = []\n",
    "    \n",
    "    for s in sentences:\n",
    "        encoded_sentences.append([START_TOKEN] + vocab_encoder.encode(s) + [END_TOKEN])\n",
    "        \n",
    "    return encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb20bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pad_data_pair(encoded_source_sentences, encoded_target_sentences, limit = MAX_SENTENCE_LEN):\n",
    "    \n",
    "    # filter over-length data\n",
    "    filtered_source_sentences = []\n",
    "    filtered_target_sentences = []\n",
    "    for source_s, target_s in zip(encoded_source_sentences, encoded_target_sentences):\n",
    "        if len(source_s) <= limit and len(target_s) <= limit:\n",
    "            filtered_source_sentences.append(source_s)\n",
    "            filtered_target_sentences.append(target_s)\n",
    "    \n",
    "    # padding length-filtered data\n",
    "    padded_source_sentences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                                filtered_source_sentences,\n",
    "                                maxlen = limit,\n",
    "                                padding = \"post\")\n",
    "    padded_target_sentences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                                filtered_target_sentences,\n",
    "                                maxlen = limit,\n",
    "                                padding = \"post\")\n",
    "    \n",
    "    return padded_source_sentences, padded_target_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd8f746",
   "metadata": {},
   "source": [
    "3-4. Define pipeline method to integer-encode and pad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a82fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pad_data(source_sentences, target_sentences, limit = MAX_SENTENCE_LEN):\n",
    "    # integer encoding\n",
    "    encoded_source_sentences = integer_encode_strings(source_sentences)\n",
    "    encoded_target_sentences = integer_encode_strings(target_sentences)\n",
    "    print(\"Total\", len(encoded_source_sentences), \"samples are successfully encoded as vocabulary indices.\")\n",
    "    \n",
    "    # filter over-length data & padding\n",
    "    padded_source_sentences, encoded_target_sentences = filter_pad_data_pair(encoded_source_sentences, encoded_target_sentences, limit)\n",
    "    print(\"Total\", len(padded_source_sentences), \"samples are successfully padded as\", limit, \"length.\")\n",
    "    \n",
    "    return padded_source_sentences, encoded_target_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a7792",
   "metadata": {},
   "source": [
    "### 4. Integer-encode and pad data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b9d80ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 11823 samples are successfully encoded as vocabulary indices.\n",
      "Total 11823 samples are successfully padded as 40 length.\n",
      "================================================================================\n",
      "< Preview of sample data >\n",
      "--------------------------------------------------------------------------------\n",
      "Q 10198 : [8112   61  196   42 5579 7888  114   23 1180 1572    1 8113    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "A 10198 : [8112 5055 7888  514  108  238 5875    1 8113    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "--------------------------------------------------------------------------------\n",
      "Q 7052 : [8112 2244  967  552   16 4640    2 8113    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "A 7052 : [8112 3076  964  291 3063    1 8113    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "--------------------------------------------------------------------------------\n",
      "Q 4971 : [8112 5873 7888 4706   55 8113    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "A 4971 : [8112  373 5873   12  891  399 3052   17    1 8113    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "source_data, target_data = encode_pad_data(questions, answers)\n",
    "\n",
    "# preview of encoded sample data\n",
    "print_double_divider()\n",
    "print(\"< Preview of sample data >\")\n",
    "\n",
    "random_idx = randint(1, len(source_data))\n",
    "print_single_divider()\n",
    "print(\"Q\", random_idx, \":\", source_data[random_idx - 1])\n",
    "print(\"A\", random_idx, \":\", target_data[random_idx - 1])\n",
    "\n",
    "random_idx = randint(1, len(questions))\n",
    "print_single_divider()\n",
    "print(\"Q\", random_idx, \":\", source_data[random_idx - 1])\n",
    "print(\"A\", random_idx, \":\", target_data[random_idx - 1])\n",
    "\n",
    "random_idx = randint(1, len(questions))\n",
    "print_single_divider()\n",
    "print(\"Q\", random_idx, \":\", source_data[random_idx - 1])\n",
    "print(\"A\", random_idx, \":\", target_data[random_idx - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1434dde",
   "metadata": {},
   "source": [
    "### 5. Prepare final DataFrame to adopt teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91091429",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "                        {\"inputs\" : source_data,\n",
    "                         \"dec_inputs\" : target_data[:, :-1]},\n",
    "                        {\"outputs\": target_data[:, 1:]},))\n",
    "    # START_TOKEN in target data removed for teacher forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4473850",
   "metadata": {},
   "source": [
    "### 6. Get ready to use data for transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15763b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ready to use for transformer model\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa5425",
   "metadata": {},
   "source": [
    "---\n",
    "## 🤖 Design transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d86b3",
   "metadata": {},
   "source": [
    "### 1. Additional pre-process for transformer input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d43c18",
   "metadata": {},
   "source": [
    "1-1. Implement scaled-dot product attention method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fbd846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "    \n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "    \n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "        \n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "    \n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4277c7d",
   "metadata": {},
   "source": [
    "1-2. Implement masking methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b138a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking method which create padding style masks\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "\n",
    "# masking method which create look-ahead style masks\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b2c977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n",
      "--------------------------------------------------------------------------------\n",
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# test operation of padding masking method\n",
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))\n",
    "\n",
    "print_single_divider()\n",
    "\n",
    "# test operation of look-ahead masking method\n",
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))\n",
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b3ff4b",
   "metadata": {},
   "source": [
    "1-3. Implement positional encoding layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64dbbe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "        \n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "                        position = tf.range(position, dtype = tf.float32)[:, tf.newaxis],\n",
    "                        i = tf.range(d_model, dtype = tf.float32)[tf.newaxis, :],\n",
    "                        d_model = d_model)\n",
    "        \n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis = 0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0])\n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "        \n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68754305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test operation of positional encoding layer\n",
    "sample_pos_encoding = PositionalEncoding(50, 512)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap = \"RdPu\")\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel(\"Position\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e44a54",
   "metadata": {},
   "source": [
    "1-4. Implement multi-head attetion layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a10bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, name = \"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "    \n",
    "    \n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm = [0, 2, 1, 3])\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        query = inputs[\"query\"]\n",
    "        key = inputs[\"key\"]\n",
    "        value = inputs[\"value\"]\n",
    "        mask = inputs[\"mask\"]\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        \n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "        \n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        \n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "        \n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a9dbd1",
   "metadata": {},
   "source": [
    "### 2. Design ENCODER structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef3c793",
   "metadata": {},
   "source": [
    "2-1. Implement encoding layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e60955af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name = \"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape = (None, d_model), name = \"inputs\")\n",
    "    \n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape = (1, 1, None), name = \"padding_mask\")\n",
    "    \n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "                    d_model, num_heads, name = \"attention\")({\n",
    "                        \"query\": inputs,\n",
    "                        \"key\": inputs,\n",
    "                        \"value\": inputs,\n",
    "                        \"mask\": padding_mask})\n",
    "    \n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate = dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon = 1e-6)(inputs + attention)\n",
    "    \n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units = units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units = d_model)(outputs)\n",
    "    \n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate = dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon = 1e-6)(attention + outputs)\n",
    "    \n",
    "    return tf.keras.Model(inputs = [inputs, padding_mask], outputs = outputs, name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c0c1c",
   "metadata": {},
   "source": [
    "2-2. Build encoder with layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49417a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name = \"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name = \"inputs\")\n",
    "    \n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name = \"padding_mask\")\n",
    "    \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    \n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "    \n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(units = units,\n",
    "                                d_model = d_model,\n",
    "                                num_heads = num_heads,\n",
    "                                dropout = dropout,\n",
    "                                name = \"encoder_layer_{}\".format(i),\n",
    "                               )([outputs, padding_mask])\n",
    "        \n",
    "    return tf.keras.Model(inputs = [inputs, padding_mask], outputs = outputs, name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265aa01",
   "metadata": {},
   "source": [
    "### 3. Design DECODER structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9029e2e",
   "metadata": {},
   "source": [
    "3-1. Implement decoder layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82f89a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name = \"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape = (None, d_model), name = \"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape = (None, d_model), name = \"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape = (1, None, None), name = \"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape = (1, 1, None), name = 'padding_mask')\n",
    "    \n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "                    d_model, num_heads, name = \"attention_1\")(inputs = {\n",
    "                        \"query\": inputs,\n",
    "                        \"key\": inputs,\n",
    "                        \"value\": inputs,\n",
    "                        \"mask\": look_ahead_mask})\n",
    "    \n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "    \n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "                    d_model, num_heads, name = \"attention_2\")(inputs = {\n",
    "                        \"query\": attention1,\n",
    "                        \"key\": enc_outputs,\n",
    "                        \"value\": enc_outputs,\n",
    "                        \"mask\": padding_mask})\n",
    "    \n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate = dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
    "    \n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units = units, activation = \"relu\")(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units = d_model)(outputs)\n",
    "    \n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate = dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon = 1e-6)(outputs + attention2)\n",
    "    \n",
    "    return tf.keras.Model(inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "                          outputs = outputs,\n",
    "                          name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44240b90",
   "metadata": {},
   "source": [
    "3-2. Build decoder with layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f65a2158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name = \"decoder\"):\n",
    "    inputs = tf.keras.Input(shape = (None,), name = \"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape = (None, d_model), name = \"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape = (1, None, None), name = \"look_ahead_mask\")\n",
    "    \n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape = (1, 1, None), name = \"padding_mask\")\n",
    "    \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    \n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    \n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(units = units,\n",
    "                                d_model = d_model,\n",
    "                                num_heads = num_heads,\n",
    "                                dropout = dropout,\n",
    "                                name = \"decoder_layer_{}\".format(i),\n",
    "                               )(inputs = [outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "        \n",
    "    return tf.keras.Model(inputs = [inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "                          outputs = outputs,\n",
    "                          name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75374ea5",
   "metadata": {},
   "source": [
    "## 4. Build transformer by combining each function block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1727dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, units, d_model, num_heads, dropout, name = \"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name = \"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name = \"dec_inputs\")\n",
    "    \n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "                            create_padding_mask,\n",
    "                            output_shape = (1, 1, None),\n",
    "                            name = \"enc_padding_mask\")(inputs)\n",
    "    \n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "                            create_look_ahead_mask,\n",
    "                            output_shape = (1, None, None),\n",
    "                            name = \"look_ahead_mask\")(dec_inputs)\n",
    "    \n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "                            create_padding_mask,\n",
    "                            output_shape = (1, 1, None),\n",
    "                            name = \"dec_padding_mask\")(inputs)\n",
    "    \n",
    "    # 인코더\n",
    "    enc_outputs = encoder(vocab_size = vocab_size,\n",
    "                          num_layers = num_layers,\n",
    "                          units = units,\n",
    "                          d_model = d_model,\n",
    "                          num_heads = num_heads,\n",
    "                          dropout = dropout,\n",
    "                         )(inputs = [inputs, enc_padding_mask])\n",
    "    \n",
    "    # 디코더\n",
    "    dec_outputs = decoder(vocab_size = vocab_size,\n",
    "                          num_layers = num_layers,\n",
    "                          units = units,\n",
    "                          d_model = d_model,\n",
    "                          num_heads = num_heads,\n",
    "                          dropout = dropout,\n",
    "                         )(inputs = [dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "    \n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units = vocab_size, name = \"outputs\")(dec_outputs)\n",
    "    \n",
    "    return tf.keras.Model(inputs = [inputs, dec_inputs], outputs = outputs, name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f97c530",
   "metadata": {},
   "source": [
    "# 일단 여기까지는 OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68560476",
   "metadata": {},
   "source": [
    "## 5. Define additional functions to test transformer performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510aa7e",
   "metadata": {},
   "source": [
    "5-1. Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adab557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape = (-1, MAX_SENTENCE_LEN - 1))\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                from_logits = True, reduction = \"none\")(y_true, y_pred)\n",
    "    \n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0172d85e",
   "metadata": {},
   "source": [
    "5-2. Define accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e64d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape = (-1, MAX_SENTENCE_LEN - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccf15bf",
   "metadata": {},
   "source": [
    "5-3. Implement custom learning rate class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b850743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \n",
    "    def __init__(self, d_model, warmup_steps = 4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        \n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "468f494e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test operation of custom learning rate\n",
    "sample_learning_rate = CustomSchedule(d_model = 128)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype = tf.float32)), color = \"pink\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0123db0",
   "metadata": {},
   "source": [
    "5-4. Define method to get predicted answer for input question using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "823b44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    # pre-process of input sentence\n",
    "    sentence = divide_punctuations(sentence)\n",
    "    \n",
    "    # integer-encode sentence & add START/END tokens\n",
    "    sentence = tf.expand_dims(\n",
    "        [START_TOKEN] + vocab_encoder.encode(sentence) + [END_TOKEN], axis = 0)\n",
    "    \n",
    "    # save past output sequence predicted by decoder\n",
    "    # initial value is START_TOKEN\n",
    "    output_sequence = tf.expand_dims([START_TOKEN], 0)\n",
    "    \n",
    "    # predict proper answer(reaction of chatbot)\n",
    "    for i in range(MAX_SENTENCE_LEN):\n",
    "        # keep predicting words (until the length becomes MAX_SENTNECE_LEN in maximum case)\n",
    "        predictions = model(inputs = [sentence, output_sequence], training = False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        \n",
    "        # integer index of currently predicted word\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis = -1), tf.int32)\n",
    "        \n",
    "        # stop prediction when END token is predicted\n",
    "        if tf.equal(predicted_id, END_TOKEN):\n",
    "            break\n",
    "            \n",
    "        # add predicted words to output sequence\n",
    "        # output sequence might be the next input of decoder\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis = -1)\n",
    "        \n",
    "    return tf.squeeze(output_sequence, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63308a81",
   "metadata": {},
   "source": [
    "5-5. Define method to decode integer-incoded sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4a8eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # get encoded prediction of answer(reaction of chatbot)\n",
    "    encoded_pred = decoder_inference(sentence)\n",
    "    \n",
    "    # decode encoded prediction (integer -> string)\n",
    "    decoded_pred = vocab_encoder.decode(\n",
    "                            [i for i in encoded_pred if i < VOCAB_SIZE - 2])    # exclude START/END tokens\n",
    "    \n",
    "    # print predicted result\n",
    "    print(\"Your said   :\", sentence)\n",
    "    print(\"Bot replies :\", decoded_pred)\n",
    "    \n",
    "    return decoded_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd9657",
   "metadata": {},
   "source": [
    "---\n",
    "## 🤖 Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a28cd",
   "metadata": {},
   "source": [
    "### 1. Generate transformer model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9e5699d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3131392     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3658752     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8114)   2085298     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,875,442\n",
      "Trainable params: 8,875,442\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# generate instance of transformer model\n",
    "model = transformer(vocab_size = VOCAB_SIZE, \n",
    "                    num_layers = NUM_LAYERS,\n",
    "                    units = UNITS,\n",
    "                    d_model = D_MODEL,\n",
    "                    num_heads = NUM_HEADS,\n",
    "                    dropout = DROPOUT)\n",
    "\n",
    "# overview of model structure\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef0736d",
   "metadata": {},
   "source": [
    "### 2. Compile transformer model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e43b0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get learning rate and optimizer\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)\n",
    "\n",
    "# complie model\n",
    "model.compile(optimizer = optimizer, loss = loss_function, metrics = [accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14020b6",
   "metadata": {},
   "source": [
    "### 3. Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b9c027a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "185/185 [==============================] - 16s 52ms/step - loss: 1.4556 - accuracy: 0.0246\n",
      "Epoch 2/200\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 1.1800 - accuracy: 0.0493\n",
      "Epoch 3/200\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.9980 - accuracy: 0.0505\n",
      "Epoch 4/200\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.9233 - accuracy: 0.0541\n",
      "Epoch 5/200\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.8666 - accuracy: 0.0573\n",
      "Epoch 6/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.8081 - accuracy: 0.0611\n",
      "Epoch 7/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.7435 - accuracy: 0.0670\n",
      "Epoch 8/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.6724 - accuracy: 0.0744\n",
      "Epoch 9/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.5936 - accuracy: 0.0836\n",
      "Epoch 10/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.5116 - accuracy: 0.0928\n",
      "Epoch 11/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.4287 - accuracy: 0.1027\n",
      "Epoch 12/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.3475 - accuracy: 0.1138\n",
      "Epoch 13/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.2734 - accuracy: 0.1248\n",
      "Epoch 14/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.2073 - accuracy: 0.1348\n",
      "Epoch 15/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.1542 - accuracy: 0.1441\n",
      "Epoch 16/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.1117 - accuracy: 0.1516\n",
      "Epoch 17/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0807 - accuracy: 0.1574\n",
      "Epoch 18/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0624 - accuracy: 0.1606\n",
      "Epoch 19/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0520 - accuracy: 0.1625\n",
      "Epoch 20/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0460 - accuracy: 0.1632\n",
      "Epoch 21/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0426 - accuracy: 0.1640\n",
      "Epoch 22/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0410 - accuracy: 0.1641\n",
      "Epoch 23/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0374 - accuracy: 0.1649\n",
      "Epoch 24/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0315 - accuracy: 0.1662\n",
      "Epoch 25/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0285 - accuracy: 0.1671\n",
      "Epoch 26/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0251 - accuracy: 0.1678\n",
      "Epoch 27/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0230 - accuracy: 0.1684\n",
      "Epoch 28/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0207 - accuracy: 0.1690\n",
      "Epoch 29/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0181 - accuracy: 0.1696\n",
      "Epoch 30/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0170 - accuracy: 0.1701\n",
      "Epoch 31/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0159 - accuracy: 0.1702\n",
      "Epoch 32/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0149 - accuracy: 0.1705\n",
      "Epoch 33/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0137 - accuracy: 0.1707\n",
      "Epoch 34/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0128 - accuracy: 0.1709\n",
      "Epoch 35/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0117 - accuracy: 0.1713\n",
      "Epoch 36/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0109 - accuracy: 0.1715\n",
      "Epoch 37/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0109 - accuracy: 0.1716\n",
      "Epoch 38/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0102 - accuracy: 0.1717\n",
      "Epoch 39/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0095 - accuracy: 0.1719\n",
      "Epoch 40/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0087 - accuracy: 0.1720\n",
      "Epoch 41/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0086 - accuracy: 0.1720\n",
      "Epoch 42/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0082 - accuracy: 0.1722\n",
      "Epoch 43/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0077 - accuracy: 0.1723\n",
      "Epoch 44/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0076 - accuracy: 0.1724\n",
      "Epoch 45/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0073 - accuracy: 0.1723\n",
      "Epoch 46/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0069 - accuracy: 0.1726\n",
      "Epoch 47/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0068 - accuracy: 0.1725\n",
      "Epoch 48/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0064 - accuracy: 0.1727\n",
      "Epoch 49/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0061 - accuracy: 0.1726\n",
      "Epoch 50/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0058 - accuracy: 0.1727\n",
      "Epoch 51/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0059 - accuracy: 0.1728\n",
      "Epoch 52/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0056 - accuracy: 0.1728\n",
      "Epoch 53/200\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.0053 - accuracy: 0.1728\n",
      "Epoch 54/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0051 - accuracy: 0.1729\n",
      "Epoch 55/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0052 - accuracy: 0.1728\n",
      "Epoch 56/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0049 - accuracy: 0.1729\n",
      "Epoch 57/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0048 - accuracy: 0.1729\n",
      "Epoch 58/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0048 - accuracy: 0.1729\n",
      "Epoch 59/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0044 - accuracy: 0.1730\n",
      "Epoch 60/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0044 - accuracy: 0.1730\n",
      "Epoch 61/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0044 - accuracy: 0.1730\n",
      "Epoch 62/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0043 - accuracy: 0.1730\n",
      "Epoch 63/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0042 - accuracy: 0.1730\n",
      "Epoch 64/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0042 - accuracy: 0.1731\n",
      "Epoch 65/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0038 - accuracy: 0.1732\n",
      "Epoch 66/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0038 - accuracy: 0.1731\n",
      "Epoch 67/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0038 - accuracy: 0.1731\n",
      "Epoch 68/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0037 - accuracy: 0.1731\n",
      "Epoch 69/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0035 - accuracy: 0.1731\n",
      "Epoch 70/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0036 - accuracy: 0.1731\n",
      "Epoch 71/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0033 - accuracy: 0.1732\n",
      "Epoch 72/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0033 - accuracy: 0.1732\n",
      "Epoch 73/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0032 - accuracy: 0.1732\n",
      "Epoch 74/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0033 - accuracy: 0.1732\n",
      "Epoch 75/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0031 - accuracy: 0.1733\n",
      "Epoch 76/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0030 - accuracy: 0.1732\n",
      "Epoch 77/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0030 - accuracy: 0.1733\n",
      "Epoch 78/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0029 - accuracy: 0.1733\n",
      "Epoch 79/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0028 - accuracy: 0.1733\n",
      "Epoch 80/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0029 - accuracy: 0.1733\n",
      "Epoch 81/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0027 - accuracy: 0.1733\n",
      "Epoch 82/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0026 - accuracy: 0.1733\n",
      "Epoch 83/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0028 - accuracy: 0.1733\n",
      "Epoch 84/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0026 - accuracy: 0.1733\n",
      "Epoch 85/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0026 - accuracy: 0.1733\n",
      "Epoch 86/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0026 - accuracy: 0.1733\n",
      "Epoch 87/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0026 - accuracy: 0.1733\n",
      "Epoch 88/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0025 - accuracy: 0.1733\n",
      "Epoch 89/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0025 - accuracy: 0.1733\n",
      "Epoch 90/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0024 - accuracy: 0.1733\n",
      "Epoch 91/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0023 - accuracy: 0.1734\n",
      "Epoch 92/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0024 - accuracy: 0.1733\n",
      "Epoch 93/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0022 - accuracy: 0.1733\n",
      "Epoch 94/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1734\n",
      "Epoch 95/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0023 - accuracy: 0.1733\n",
      "Epoch 96/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1734\n",
      "Epoch 97/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0020 - accuracy: 0.1734\n",
      "Epoch 98/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1734\n",
      "Epoch 99/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0022 - accuracy: 0.1734\n",
      "Epoch 100/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0020 - accuracy: 0.1733\n",
      "Epoch 101/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0019 - accuracy: 0.1734\n",
      "Epoch 102/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1734\n",
      "Epoch 103/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1733\n",
      "Epoch 104/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1734\n",
      "Epoch 105/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0020 - accuracy: 0.1734\n",
      "Epoch 106/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1734\n",
      "Epoch 107/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1734\n",
      "Epoch 108/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0019 - accuracy: 0.1734\n",
      "Epoch 109/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1734\n",
      "Epoch 110/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0018 - accuracy: 0.1734\n",
      "Epoch 111/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0020 - accuracy: 0.1733\n",
      "Epoch 112/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0015 - accuracy: 0.1734\n",
      "Epoch 113/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0019 - accuracy: 0.1734\n",
      "Epoch 114/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0021 - accuracy: 0.1733\n",
      "Epoch 115/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1734\n",
      "Epoch 116/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0016 - accuracy: 0.1734\n",
      "Epoch 117/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0017 - accuracy: 0.1734\n",
      "Epoch 118/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0017 - accuracy: 0.1734\n",
      "Epoch 119/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1734\n",
      "Epoch 120/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0017 - accuracy: 0.1734\n",
      "Epoch 121/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0016 - accuracy: 0.1734\n",
      "Epoch 122/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1734\n",
      "Epoch 123/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1734\n",
      "Epoch 124/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0016 - accuracy: 0.1734\n",
      "Epoch 125/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0016 - accuracy: 0.1734\n",
      "Epoch 126/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1734\n",
      "Epoch 127/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1735\n",
      "Epoch 128/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0017 - accuracy: 0.1734\n",
      "Epoch 129/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0015 - accuracy: 0.1734\n",
      "Epoch 130/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0015 - accuracy: 0.1735\n",
      "Epoch 131/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1734\n",
      "Epoch 132/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0015 - accuracy: 0.1734\n",
      "Epoch 133/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0014 - accuracy: 0.1735\n",
      "Epoch 134/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1735\n",
      "Epoch 135/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0015 - accuracy: 0.1734\n",
      "Epoch 136/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1734\n",
      "Epoch 137/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1735\n",
      "Epoch 138/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1735\n",
      "Epoch 139/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0014 - accuracy: 0.1734\n",
      "Epoch 140/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 141/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 142/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0014 - accuracy: 0.1735\n",
      "Epoch 143/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 144/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0014 - accuracy: 0.1735\n",
      "Epoch 145/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 146/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 147/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 148/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 149/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 150/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 151/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1734\n",
      "Epoch 152/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 153/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 154/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 155/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 156/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 157/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 158/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0015 - accuracy: 0.1734\n",
      "Epoch 159/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 160/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 161/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 162/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1735\n",
      "Epoch 163/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 164/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 165/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 166/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 167/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 168/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1734\n",
      "Epoch 169/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 170/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 171/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1734\n",
      "Epoch 172/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0013 - accuracy: 0.1734\n",
      "Epoch 173/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 174/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 175/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 176/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 177/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 178/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 179/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 180/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1735\n",
      "Epoch 181/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0010 - accuracy: 0.1735\n",
      "Epoch 182/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0010 - accuracy: 0.1735\n",
      "Epoch 183/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 184/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0011 - accuracy: 0.1734\n",
      "Epoch 185/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0010 - accuracy: 0.1735\n",
      "Epoch 186/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0010 - accuracy: 0.1735\n",
      "Epoch 187/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0012 - accuracy: 0.1735\n",
      "Epoch 188/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 189/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 190/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 191/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 192/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 193/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 194/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 195/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 196/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1735\n",
      "Epoch 197/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0011 - accuracy: 0.1735\n",
      "Epoch 198/200\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0010 - accuracy: 0.1735\n",
      "Epoch 199/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0010 - accuracy: 0.1735\n",
      "Epoch 200/200\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0012 - accuracy: 0.1735\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs = EPOCHS, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699bd556",
   "metadata": {},
   "source": [
    "### 4. Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c77d11ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Welcome to my chatbot world!\n",
      "\n",
      "Your said   : 지금 몇시야?\n",
      "Bot replies : 간단한 견과류나 과일을 먹어보세요 .\n",
      "--------------------------------------------------------------------------------\n",
      "Your said   : 오늘 점심 메뉴 추천해줘\n",
      "Bot replies : 누구랑 먹는 냐에 따라 다르겠죠 .\n",
      "--------------------------------------------------------------------------------\n",
      "Your said   : 요즘 날씨가 너무 춥다\n",
      "Bot replies : 이별에는 면역이 힘든가봐요 .\n",
      "--------------------------------------------------------------------------------\n",
      "Your said   : 주말에는 청소를 할거야\n",
      "Bot replies : 같이 안해보세요 .\n",
      "--------------------------------------------------------------------------------\n",
      "Your said   : 크리스마스 선물은 뭐가 좋을까?\n",
      "Bot replies : 항상 못해본 건 궁금하더라고요 .\n",
      "--------------------------------------------------------------------------------\n",
      "Your said   : 인터넷 쇼핑을 했는데 얼른 택배 왔으면 좋겠다\n",
      "Bot replies : 사이즈를 잘 보고 사세요 .\n",
      "--------------------------------------------------------------------------------\n",
      "Your said   : 내일은 어떤 공부를 하게 될까?\n",
      "Bot replies : 기우제를 지내봅시다 !\n",
      "--------------------------------------------------------------------------------\n",
      "Your said   : 너는 취미가 뭐야?\n",
      "Bot replies : 받는 것보다 주는 게 더 행복하고\n",
      "--------------------------------------------------------------------------------\n",
      "Your said   : 나는 고양이보다 강아지가 더 좋아\n",
      "Bot replies : 분위기 있네요 .\n",
      "--------------------------------------------------------------------------------\n",
      "Your said   : 사실은 말할 수 없는 비밀이 있어\n",
      "Bot replies : 그런 일은 하지 마세요 .\n",
      "--------------------------------------------------------------------------------\n",
      "Your said   : 우리 이제는 사랑하게 될거야\n",
      "Bot replies : 정말 특이한 사람 많죠 .\n"
     ]
    }
   ],
   "source": [
    "print(\">>> Welcome to my chatbot world!\\n\")\n",
    "\n",
    "question = \"지금 몇시야?\"\n",
    "answer = sentence_generation(question)\n",
    "\n",
    "print_single_divider()\n",
    "question = \"오늘 점심 메뉴 추천해줘\"\n",
    "answer = sentence_generation(question)\n",
    "\n",
    "print_single_divider()\n",
    "question = \"요즘 날씨가 너무 춥다\"\n",
    "answer = sentence_generation(question)\n",
    "\n",
    "print_single_divider()\n",
    "question = \"주말에는 청소를 할거야\"\n",
    "answer = sentence_generation(question)\n",
    "\n",
    "print_single_divider()\n",
    "question = \"크리스마스 선물은 뭐가 좋을까?\"\n",
    "answer = sentence_generation(question)\n",
    "\n",
    "print_single_divider()\n",
    "question = \"인터넷 쇼핑을 했는데 얼른 택배 왔으면 좋겠다\"\n",
    "answer = sentence_generation(question)\n",
    "\n",
    "print_single_divider()\n",
    "question = \"내일은 어떤 공부를 하게 될까?\"\n",
    "answer = sentence_generation(question)\n",
    "\n",
    "print_single_divider()\n",
    "question = \"너는 취미가 뭐야?\"\n",
    "answer = sentence_generation(question)\n",
    "\n",
    "print_single_divider()\n",
    "question = \"나는 고양이보다 강아지가 더 좋아\"\n",
    "answer = sentence_generation(question)\n",
    "\n",
    "print_single_divider()\n",
    "question = \"사실은 말할 수 없는 비밀이 있어\"\n",
    "answer = sentence_generation(question)\n",
    "\n",
    "print_single_divider()\n",
    "question = \"우리 이제는 사랑하게 될거야\"\n",
    "answer = sentence_generation(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c12e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "이제 exploration이 끝난ㄴ 거 같아서 기분이 좋고 주말에 얼른 밀린걸 매꿔야겠다\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
